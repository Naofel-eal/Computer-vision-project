{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition du seuil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: [Fine tuning the threshold in face recognition](https://sefiks.com/2020/05/22/fine-tuning-the-threshold-in-face-recognition/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des identitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import cv2\n",
    "from chefboost import Chefboost as chef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing as mp\n",
    "current_dir = os.getcwd()\n",
    "new_dir = current_dir.replace(\"\\\\tests\", \"\")\n",
    "os.chdir(new_dir)\n",
    "\n",
    "from services.faces.face_detector import FaceDetector\n",
    "from services.faces.comparators.yolo_comparator import YoloComparator\n",
    "from services.images.image_editor import ImageEditor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"C:\\\\Users\\\\Naofel\\\\Downloads\\\\VGG-Face2\\\\exp10\\\\val\"\n",
    "\n",
    "def get_person_files(dataset_root) -> dict:\n",
    "    person_files = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(dataset_root):\n",
    "        for dir in dirs:\n",
    "            person_name = dir\n",
    "            person_dir = os.path.join(root, dir)\n",
    "            person_files[person_name] = []\n",
    "\n",
    "            for file in os.listdir(person_dir):\n",
    "                if file.endswith(\".jpg\"):\n",
    "                    person_files[person_name].append(dir + '\\\\' + file)\n",
    "\n",
    "    return person_files\n",
    "\n",
    "identities = get_person_files(dataset_root)\n",
    "\n",
    "print(identities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de paires positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = []\n",
    "for key, values in identities.items():\n",
    "    for i in range(0, len(values)-1):\n",
    "        for j in range(i+1, len(values)):\n",
    "            positives.append([values[i], values[j]])\n",
    "\n",
    "positives = pd.DataFrame(positives, columns = [\"file_x\", \"file_y\"])\n",
    "positives[\"decision\"] = \"Yes\"\n",
    "\n",
    "positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération de paires négatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_list = list(identities.values())\n",
    "\n",
    "negatives = []\n",
    "for i in range(0, len(identities) - 1):\n",
    "    for j in range(i+1, len(identities)):\n",
    "        cross_product = itertools.product(samples_list[i], samples_list[j])\n",
    "        cross_product = list(cross_product)\n",
    "\n",
    "    for cross_sample in cross_product:\n",
    "        negatives.append([cross_sample[0], cross_sample[1]])\n",
    "\n",
    "negatives = pd.DataFrame(negatives, columns = [\"file_x\", \"file_y\"])\n",
    "negatives[\"decision\"] = \"No\"\n",
    "\n",
    "negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.concat([positives, negatives]).reset_index(drop = True)\n",
    "df.file_x = df.file_x\n",
    "df.file_y = df.file_y\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distances between pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_comparator = YoloComparator()\n",
    "face_detector = FaceDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(distances))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete lines with distance < 0.1 because they are probably the same person\n",
    "\n",
    "print(\"Before:\", len(df))\n",
    "df = df[df[\"distance\"] >= 0.1]\n",
    "print(\"After:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_mean = round(df[df.decision == \"Yes\"][\"distance\"].mean(), 4)\n",
    "tp_std = round(df[df.decision == \"Yes\"][\"distance\"].std(), 4)\n",
    "fp_mean = round(df[df.decision == \"No\"][\"distance\"].mean(), 4)\n",
    "fp_std = round(df[df.decision == \"No\"][\"distance\"].std(), 4)\n",
    "\n",
    "print(f\"True positive mean: {tp_mean} - True positive std: {tp_std}\")\n",
    "print(f\"False positive mean: {fp_mean} - False positive std: {fp_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.decision == \"Yes\"].distance.plot.kde()\n",
    "df[df.decision == \"No\"].distance.plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treshold calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_2_threshold = round(tp_mean + 2 * tp_std, 4) # Corresponds to 95.45% confidence \n",
    "sigma_3_threshold = round(tp_mean + 3 * tp_std, 4) # Corresponds to 99.73% confidence\n",
    "print(f\"2 Sigma threshold: {sigma_2_threshold}\")\n",
    "print(f\"3 Sigma threshold: {sigma_3_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an output folder and a rules.py file containing the calculated threshold\n",
    "\n",
    "config = {'algorithm': 'C4.5'}\n",
    "tmp_df = df[['distance', 'decision']].rename(columns={\"decision\": \"Decision\"}).copy()\n",
    "print(tmp_df)\n",
    "model = chef.fit(df=tmp_df, config=config, target_label='decision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_threshold = 0.3336793708127679"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"prediction\"] = \"No\"\n",
    "\n",
    "df.loc[df.distance <= decision_tree_threshold, 'decision_tree_prediction'] = 'Yes'\n",
    "df.loc[df.distance <= sigma_2_threshold, 'sigma_2_prediction'] = 'Yes'\n",
    "df.loc[df.distance <= sigma_3_threshold, 'sigma_3_prediction'] = 'Yes'\n",
    "df.loc[df.distance > decision_tree_threshold, 'decision_tree_prediction'] = 'No'\n",
    "df.loc[df.distance > sigma_2_threshold, 'sigma_2_prediction'] = 'No'\n",
    "df.loc[df.distance > sigma_3_threshold, 'sigma_3_prediction'] = 'No'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_cm = confusion_matrix(df.decision.values, df.decision_tree_prediction.values)\n",
    "sigma_2_cm = confusion_matrix(df.decision.values, df.sigma_2_prediction.values)\n",
    "sigma_3_cm = confusion_matrix(df.decision.values, df.sigma_3_prediction.values)\n",
    "\n",
    "def plot_cm_with_metrics(cm, title, threshold):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    plt.figure(figsize=(cm.shape[0] + 2, cm.shape[1]))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    heatmap(cm, annot=True, fmt=\"d\", cmap=\"RdYlBu_r\")\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.axis('off')\n",
    "    plt.text(0, 0.8, f\"Recall: {recall:.3f}\", fontsize=10, ha='left')\n",
    "    plt.text(0, 0.6, f\"Precision: {precision:.3f}\", fontsize=10, ha='left')\n",
    "    plt.text(0, 0.4, f\"Accuracy: {accuracy:.3f}\", fontsize=10, ha='left')\n",
    "    plt.text(0, 0.2, f\"F1: {f1:.3f}\", fontsize=10, ha='left')\n",
    "    plt.text(0, 0, f\"Threshold: {threshold:.4f}\", fontsize=10, ha='left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_cm_with_metrics(decision_tree_cm, \"Decision tree confusion matrix\", threshold=decision_tree_threshold)\n",
    "plot_cm_with_metrics(sigma_2_cm, \"2-Sigma confusion matrix\", threshold=sigma_2_threshold)\n",
    "plot_cm_with_metrics(sigma_3_cm, \"3-Sigma confusion matrix\", threshold=sigma_3_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
